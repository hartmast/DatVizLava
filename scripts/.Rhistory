prob_drink <- 0.2 # 20% of days
rate_work <- 1 # average 1 manuscript per day
# sample one year of production
N <- 365
# simulate days on which the monks drink
set.seed(365)
drink <- rbinom(N, 1, prob_drink)
# simulate number of completed manuscripts
y <- (1-drink)*rpois(N, rate_work)
# visualize
hist(y)
table(y) %>% barplot() # many days on which the monks produce 0 manuscripts!
# dataframe
monks <- tibble(drink = drink,
manuscripts = y)
ggplot(monks, aes(x = manuscripts, fill = factor(drink), group = factor(drink))) + geom_bar(position = "dodge")
m_monks <- zeroinfl(manuscripts ~ factor(drink), data = monks)
summary(m_monks)
d <- read_csv("../data/nettle_1999_climate.csv")
ggplot(d, aes(x = MGS, y = Langs)) +
geom_point() + geom_smooth(method = MASS::glm.nb)
# fit model
m <- glm.nb(Langs ~ MGS + offset(Area), data = d)
# model summary
summary(m)
# compare with model without MGS
m0 <- glm.nb(Langs ~ 1 + offset(Area), data = d)
anova(m, m0)
# fit a negative binomial model
m2 <- glm.nb(errors ~ year + subject + gender, data = d)
library(tidyverse)
library(pscl)
library(MASS)
library(lme4)
library(effects)
library(glmmTMB)
# read data ---------------------------------------------------------------
d <- read_csv("../data/graphvar_summary_1980ff.csv")
# grades:
d$grade %>% hist
# errors:
d$errors %>% hist
# zeros?
any(d$errors==0)
# minimum and maximum
range(d$errors)
# fit a Poisson model
m <- glm(errors ~ year + subject,
family = "poisson", data = d)
summary(m)
# test for overdispersion
pr <- resid(m, type = "pearson") # residuals
pchi2 <- sum(residuals(m, type="pearson")^2) #Pearson chi-squared
disp <- pchi2/m$df.residual # Pearson disperson statistic
pchi2; disp
# fit a negative binomial model
m2 <- glm.nb(errors ~ year + subject + gender, data = d)
summary(m2)
# fit a Poisson model
m <- glm(errors ~ year + subject + gender,
family = "poisson", data = d)
summary(m)
# test for overdispersion
pr <- resid(m, type = "pearson") # residuals
pchi2 <- sum(residuals(m, type="pearson")^2) #Pearson chi-squared
disp <- pchi2/m$df.residual # Pearson disperson statistic
pchi2; disp
ggplot(d, aes(x = gender, y = errors)) + geom_boxplot()
log(d$errors) / log(d$tokens)
log(d$errors) / log(d$tokens) %>% hist
log(d$errors) / log(d$tokens)
?offset
offset(d$tokens)
offset(d$tokens) %>% hist
library(AER)
library(AER)
?dispersiontest
########################
# Modeling count data  #
########################
# libraries ---------------------------------------------------------------
library(tidyverse)
library(glmmTMB)
library(MASS)
library(pscl)
library(effects)
library(vcd)
library(car)
library(readxl)
library(ggbeeswarm)
library(VGAM)
library(AER)
# fake data ---------------------------------------------------------------
set.seed(utf8ToInt("Ascona"))
counts <- rpois(100, lambda = 2)
counts2 <- rpois(100, lambda = 1)
# dataframe
df <- tibble(category = c(rep("A", 100), rep("B", 100)),
count = c(counts, counts2))
# plot
ggplot(df, aes(x = category, y = count)) +
geom_boxplot()
# model
m <- glm(count ~ category, family = "poisson", data = df)
summary(m)
plot(allEffects(m))
# check assumptions
# how many zeros does the model predict?
# The predict() function returns the means that
# the model estimates.
preds <- predict(m, type = "response")
preds
# the density distribution function (for Poisson: dpois)
# returns the probability that the observation
# is equal to a given value, given the current
# lambda value.
sum(dpois(x=0, lambda = preds)) # ca. 50 zeros expected
# calculate Pearson chisquare & Pearson dispersion
# Pearson dispersion value of 0 indicates a "true"
# Poisson distribution. Higher values indicate
# overdisperson, lower values indicate under-
# dispersion.
pr <- resid(m, type = "pearson") # residuals
pchi2 <- sum(residuals(m, type="pearson")^2) #Pearson chi-squared
disp <- pchi2/m$df.residual # Pearson disperson statistic
pchi2; disp
# AER package has a test for over-/underdispersion:
dispersiontest(m)
160/1949
160/9049
548/14781
548/(14781+548)
160/(9049+160)
library(tidyverse)
library(pscl)
library(MASS)
library(lme4)
library(effects)
library(glmmTMB)
library(AER)
# read data ---------------------------------------------------------------
d <- read_csv("../data/graphvar_summary_1980ff.csv")
# grades:
d$grade %>% hist
# errors:
d$errors %>% hist
# zeros?
any(d$errors==0)
# minimum and maximum
range(d$errors)
# fit a Poisson model
m <- glm(errors ~ year + subject + gender,
family = "poisson", data = d)
summary(m)
# test for overdispersion
pr <- resid(m, type = "pearson") # residuals
pchi2 <- sum(residuals(m, type="pearson")^2) #Pearson chi-squared
disp <- pchi2/m$df.residual # Pearson disperson statistic
pchi2; disp
dispersiontest(m)
# fit a negative binomial model
m2 <- glm.nb(errors ~ year + subject + gender, data = d)
summary(m2)
dispersiontest(m)
########################
# Modeling count data  #
########################
# libraries ---------------------------------------------------------------
library(tidyverse)
library(glmmTMB)
library(MASS)
library(pscl)
library(effects)
library(vcd)
library(car)
library(readxl)
library(ggbeeswarm)
library(VGAM)
library(AER)
# fake data ---------------------------------------------------------------
set.seed(utf8ToInt("Ascona"))
counts <- rpois(100, lambda = 2)
counts2 <- rpois(100, lambda = 1)
# dataframe
df <- tibble(category = c(rep("A", 100), rep("B", 100)),
count = c(counts, counts2))
# plot
ggplot(df, aes(x = category, y = count)) +
geom_boxplot()
# model
m <- glm(count ~ category, family = "poisson", data = df)
summary(m)
plot(allEffects(m))
# check assumptions
# how many zeros does the model predict?
# The predict() function returns the means that
# the model estimates.
preds <- predict(m, type = "response")
preds
# the density distribution function (for Poisson: dpois)
# returns the probability that the observation
# is equal to a given value, given the current
# lambda value.
sum(dpois(x=0, lambda = preds)) # ca. 50 zeros expected
# calculate Pearson chisquare & Pearson dispersion
# Pearson dispersion value of 0 indicates a "true"
# Poisson distribution. Higher values indicate
# overdisperson, lower values indicate under-
# dispersion.
pr <- resid(m, type = "pearson") # residuals
pchi2 <- sum(residuals(m, type="pearson")^2) #Pearson chi-squared
disp <- pchi2/m$df.residual # Pearson disperson statistic
pchi2; disp
# AER package has a test for over-/underdispersion:
dispersiontest(m) # null hypothesis: equidispersion
# AER package has a test for over-/underdispersion:
dispersiontest(m, alt = "two.sided") # null hypothesis: equidispersion
library(tidyverse)
library(pscl)
library(MASS)
library(lme4)
library(effects)
library(glmmTMB)
library(AER)
# read data ---------------------------------------------------------------
d <- read_csv("../data/graphvar_summary_1980ff.csv")
# grades:
d$grade %>% hist
# errors:
d$errors %>% hist
# zeros?
any(d$errors==0)
# minimum and maximum
range(d$errors)
# fit a Poisson model
m <- glm(errors ~ year + subject + gender,
family = "poisson", data = d)
summary(m)
# test for overdispersion
pr <- resid(m, type = "pearson") # residuals
pchi2 <- sum(residuals(m, type="pearson")^2) #Pearson chi-squared
disp <- pchi2/m$df.residual # Pearson disperson statistic
pchi2; disp
dispersiontest(m)
# fit a negative binomial model
m2 <- glm.nb(errors ~ year + subject + gender, data = d)
summary(m2)
# also check for zero-inflation/-truncation:
# how many 0s does the model predict?
preds <- predict(m2, type = "response")
sum(dpois(x=0, lambda = preds)) %>% round
# compare with poisson model
preds <- predict(m, type = "response")
sum(dpois(x=0, lambda = preds)) %>% round
preds
library(stats)
devtools::install_github("johannabertl/SelectionMix")
library(SelectionMix)
library(SelectionMix)
library(rnegbinmix)
dnegbin(125, 7)
dnegbin(125, 7, .5)
?nbinom2()
dnegbin(125, 7, .5)
pnegbin(125, 7, .5)
?pnegbino,
?pnegbinom
?pnbinom
rnbinom(n = 125, size = 20)
rnbinom(n = 125, size = 20, prob = .2)
# get ice cream
icecream <- rnbinom(n = 125, size = 20, prob = .2)
tibble(day = 1:125,
scoops = icecream)
x <- tibble(day = 1:125,
scoops = icecream)
x
x$scoops %>% table
# get ice cream
icecream <- rnbinom(n = 125, size = 20, prob = .5)
x <- tibble(day = 1:125,
scoops = icecream)
x$scoops %>% table
# get ice cream
icecream <- rnbinom(n = 125, size = 10, prob = .8)
x <- tibble(day = 1:125,
scoops = icecream)
x$scoops %>% table
# get ice cream
icecream <- rnbinom(n = 125, size = 15, prob = .8)
x <- tibble(day = 1:125,
scoops = icecream)
x$scoops %>% table
# get ice cream
icecream <- rnbinom(n = 125, size = 30, prob = .8)
x <- tibble(day = 1:125,
scoops = icecream)
x$scoops %>% table
# get ice cream
icecream <- rnbinom(n = 125, size = 30, prob = .2)
x <- tibble(day = 1:125,
scoops = icecream)
x$scoops %>% table
# get ice cream
icecream <- rnbinom(n = 125, size = 30, prob = .5)
x <- tibble(day = 1:125,
scoops = icecream)
x$scoops %>% table
# get ice cream
icecream <- rnbinom(n = 125, size = 30, prob = .2)
x <- tibble(day = 1:125,
scoops = icecream)
x$scoops %>% table
# get ice cream
icecream_poisson <- rpois(100, 20)
# get ice cream
icecream_poisson <- rpois(125, 20)
icecream_poisson
icecream_poisson %>% table
x <- tibble(day = 1:125,
scoops = icecream_poisson)
x
x$scoops
x$scoops+2
jitter(x$scoops+2)
round(jitter(x$scoops+2))
x$temperature <- round(jitter(x$scoops+2))
plot(x$scoops, x$temperature)
?jitter
x$temperature <- round(jitter(x$scoops+2, factor = 2))
plot(x$scoops, x$temperature)
x$temperature <- round(jitter(x$scoops+2, factor = 5))
plot(x$scoops, x$temperature)
plot(x$scoops, x$temperature)
x
plot(x$temperature)
plot(x$temperature~x$scoops)
plot(x$temperature~x$scoops, type = "b")
glm(x, scoops ~ temperature, data = x)
glm(x, scoops ~ temperature, data = x, family = "poisson")
x$scoops
glm(scoops ~ temperature, data = x, family = "poisson")
glm(scoops ~ temperature, data = x, family = "poisson") %>% summary
x$scoops %>% hist
ifelse(x$scoops<=15 & x$temperature>20, "yes", "no")
ifelse(x$scoops<=15 & x$temperature>10, "yes", "no")
x$rain <- ifelse(x$scoops<=15 & x$temperature>10, "yes", "no")
glm(scoops ~ temperature+rain, data = x, family = "poisson") %>% summary
x$rain <- ifelse(x$scoops<=10 & x$temperature>10, "yes", "no")
x$scoops
glm(scoops ~ temperature+rain, data = x, family = "poisson") %>% summary
x
x$rain
x$rain %>% unique
x$rain <- ifelse(x$scoops<=10 & x$temperature>5, "yes", "no")
x$rain %>% unique
x$rain <- ifelse(x$scoops<=10 & x$temperature>20, "yes", "no")
x$rain %>% unique
x$rain <- ifelse(x$scoops<=200 & x$temperature>20, "yes", "no")
x$rain <- ifelse(x$scoops<=20 & x$temperature>20, "yes", "no")
x$rain %>% unique
glm(scoops ~ temperature+rain, data = x, family = "poisson") %>% summary
hist(x$temperature)
x$rain <- ifelse(x$scoops<=20 & x$temperature>25, "yes", "no")
x$rain %>% unique
filter(x$temperature<20)
filter(x, temperature<20)
filter(x, temperature>20)
tempover20 <- which(x$temperature>20)
x[tempover20,]
myspl <- sample(1:68, 20)
x[tempover20[spl],]
x[tempover20[myspl],]
x[tempover20[myspl],]$temperature <- sample(15:28, 1)
tempover20 <- which(x$temperature>20)
myspl <- sample(1:68, 20)
x[myspl,]$rain <- "yes"
which(x$rain=="yes")
x[which(x$rain=="yes"),]
x[which(x$rain=="yes"),]$scoops <- x[which(x$rain=="yes"),]$scoops - sample(2:5,1)
glm(scoops ~ temperature+rain, data = x, family = "poisson") %>% summary
# export
write_csv(x, "ice_cream.csv")
?log
library(tidyverse)
library(shiny)
library(stats)
# simple barplot
ui <- fluidPage(
titlePanel("Poisson"),
sliderInput(inputId = "mylambda",
label = "lambda",
value = 10, min = 1, max = 100, step = 1),
plotOutput(outputId = "reactivePlot"),
textOutput(outputId = "varianceText"),
titlePanel("Negative Binomial"),
sliderInput(inputId = "mymu",
label = "mu",
value = 10, min = 1, max = 100, step = 1),
sliderInput(inputId = "mysize",
label = "size (dispersion parameter)",
value = 10, min = 1, max = 100, step = 1),
plotOutput(outputId = "reactivePlot2"),
textOutput(outputId = "varianceText2")
)
server <- function(input, output) {
output$reactivePlot <- renderPlot({
cur <- dpois(1:200, lambda = input$mylambda)
barplot(cur, names.arg = 1:200, xlab = "count", ylab = "probability")
})
output$varianceText <- renderText({
cur <- dpois(1:200, lambda = input$mylambda)
paste0("Variance:", round(var(cur), digits = 4))
})
output$reactivePlot2 <- renderPlot({
cur <- dnbinom(1:200, mu = input$mymu, size = input$mysize)
barplot(cur, names.arg = 1:200, xlab = "count", ylab = "probability")
})
output$varianceText2 <- renderText({
cur <- dnbinom(1:200, mu = input$mylambda)
paste0("Variance:", round(var(cur), digits = 4))
}
)
}
shinyApp(ui = ui, server = server)
library(tidyverse)
library(lme4)
library(MASS)
library(pscl)
library(AER)
# ice cream consumption
d <- read_csv("../data/ice_cream.csv")
View(d)
# Poisson model
m <- glm(scoops ~ temperature + rain,
family = "poisson", data = d)
summary(m)
# calculate Pearson chisquare & Pearson dispersion
# Pearson dispersion value of 0 indicates a "true"
# Poisson distribution. Higher values indicate
# overdisperson, lower values indicate under-
# dispersion.
pr <- resid(m, type = "pearson") # residuals
pchi2 <- sum(residuals(m, type="pearson")^2) #Pearson chi-squared
disp <- pchi2/m$df.residual # Pearson disperson statistic
pchi2; disp
dispersiontest(m)
nettle <- read_csv("../data/nettle_1999_climate.csv")
View(nettle)
m1 <- glm(Langs ~ MGS, family = "poisson", data = nettle)
summary(m1)
m2 <- glm(Langs ~ MGS + offset(Area),
family = "poisson",
data = nettle)
summary(m2)
anova(m1, m2)
anova(m1, m2, test = "chisq")
anova(m1, m2, test = "Chisq")
m0 <- glm(Langs ~ 1,
family = "poisson",
data = nettle)
anova(m0, m1)
?neg.bin
?glm.nb
dispersiontest(m2)
# negative binomial regression
m_negbin <- glm.nb(Langs ~ MGS, data = nettle)
summary(m_negbin)
# negative binomial regression
m_negbin <- glm.nb(Langs ~ MGS + offset(Area),
data = nettle)
summary(m_negbin)
library(glmmTMB)
library(tidyverse)
library(pscl)
library(MASS)
library(lme4)
library(effects)
library(glmmTMB)
library(AER)
d <- read_csv("../data/graphvar_summary_1980ff.csv")
View(d)
# Poisson model:
m1 <- glm(errors ~ year + subject + gender,
family = "poisson", data = d)
summary(m1)
dispersiontest(m1)
?dispersiontest
m2 <- glm.nb(errors ~ year + subject + gender,
data = d)
summary(m2)
?scale
scale(d$year)
# grades:
d$grade %>% scale(scale = F)
# grades:
d$grade %>% scale(scale = F) %>% hist
# grades:
d$grade %>% scale(scale = T) %>% hist
scale(d$year)
scale(d$year)[[1]]
scale(d$year)
# errors:
d$errors_scaled <- d$errors %>% hist
# errors:
d$errors_scaled <- d$errors
# errors:
d$errors_scaled <- scale(d$errors)
d$year_scaled <-  scale(d$year)
m3 <- glm.nb(errors ~ year_scaled + subject + gender,
data = d)
summary(m3)
